#!/usr/bin/env python
# coding: utf-8

# # Анализ лояльности пользователей Яндекс Афиши

# ## Этапы выполнения проекта
# 
# ### 1. Загрузка данных и их предобработка
# 
# ---
# 
# **Задача 1.1:** Напишите SQL-запрос, выгружающий в датафрейм pandas необходимые данные. Используйте следующие параметры для подключения к базе данных:
# 
# удалены данные для подключения из публичного проекта
# 
# Для выгрузки используйте запрос из предыдущего урока и библиотеку SQLAlchemy.
# 
# Выгрузка из базы данных SQL должна позволить собрать следующие данные:
# 
# - `user_id` — уникальный идентификатор пользователя, совершившего заказ;
# - `device_type_canonical` — тип устройства, с которого был оформлен заказ (`mobile` — мобильные устройства, `desktop` — стационарные);
# - `order_id` — уникальный идентификатор заказа;
# - `order_dt` — дата создания заказа (используйте данные `created_dt_msk`);
# - `order_ts` — дата и время создания заказа (используйте данные `created_ts_msk`);
# - `currency_code` — валюта оплаты;
# - `revenue` — выручка от заказа;
# - `tickets_count` — количество купленных билетов;
# - `days_since_prev` — количество дней от предыдущей покупки пользователя, для пользователей с одной покупкой — значение пропущено;
# - `event_id` — уникальный идентификатор мероприятия;
# - `service_name` — название билетного оператора;
# - `event_type_main` — основной тип мероприятия (театральная постановка, концерт и так далее);
# - `region_name` — название региона, в котором прошло мероприятие;
# - `city_name` — название города, в котором прошло мероприятие.
# 
# ---
# 

# In[1]:


# Используйте ячейки типа Code для вашего кода,
# а ячейки типа Markdown для комментариев и выводов


# In[2]:


# При необходимости добавляйте новые ячейки для кода или текста


# In[3]:


import pandas as pd
from sqlalchemy import create_engine 

try:
    import phik
except ModuleNotFoundError as e:
    get_ipython().system('pip install phik')
    import phik
    print("Error was:", e)
    
import matplotlib.pyplot as plt
import seaborn as sns


# In[4]:

удалены данные для подключения из публичного проекта
--db_config = {'user': '', # имя пользователя
  --           'pwd': '', # пароль
    --         'host': '',
      --       'port':, # порт подключения
        --     'db': '' # название базы данных
          --   } 


connection_string = 'postgresql://{}:{}@{}:{}/{}'.format(
    db_config['user'],
    db_config['pwd'],
    db_config['host'],
    db_config['port'],
    db_config['db'],
) 


engine = create_engine(connection_string) 


# In[5]:


query = '''
select 
  user_id, 
  device_type_canonical,
  order_id,
  created_dt_msk as order_dt,
  created_ts_msk as order_ts,
  currency_code,
  revenue,
  tickets_count,
  (created_dt_msk::date - lag(created_dt_msk::date)over(partition by user_id order by created_dt_msk)) as days_since_prev,
  event_id,
  event_name_code as event_name,
  event_type_main,
  service_name,
  region_name,
  city_name
from afisha.purchases
join afisha.events using(event_id)
join afisha.city using(city_id)
join afisha.regions using(region_id)
where device_type_canonical in ('mobile', 'desktop')
and event_type_main != 'фильм'
order by user_id
''' 

df = pd.read_sql_query(query, con=engine) 


# ---
# 
# **Задача 1.2:** Изучите общую информацию о выгруженных данных. Оцените корректность выгрузки и объём полученных данных.
# 
# Предположите, какие шаги необходимо сделать на стадии предобработки данных — например, скорректировать типы данных.
# 
# Зафиксируйте основную информацию о данных в кратком промежуточном выводе.
# 
# ---

# In[6]:


df.head()


# In[7]:


df.info()


# In[8]:


df.isna().sum()


# In[9]:


df['user_id'].nunique()


# In[10]:


df[['revenue','days_since_prev','tickets_count']].describe()


# In[11]:


for i in ['device_type_canonical', 'currency_code', 'event_type_main', 'service_name', 'region_name', 'city_name']:
    print(f'Количество уникальных значний в {i} = {df[i].nunique()}: {df[i].sort_values().unique()}')
    print()


# Загруженный датафрейм содержит 290611 строк и 15 колонок:
# * 2 колонки типа datetime64 с информацией о дате и времени заказа
# * 2 колонки типа float64 с данными о сумме заказа и количестве дней между заказами
# * 3 колонки типа int64 с данными о идентификаторе заказа, идентификаторе мероприятия и количестве билетов
# * 8 колонок типа object с данными об идентификаторе пользователя, типе устройства, валюте оплаты и информации о продавце билетов и мероприятии
# 
# В датафрейме в колонке days_since_prev есть 21933 пустых значения - это обусловлено логикой данного поля и сведетельствует о том, что для пользователя данный заказ был первым в Яндекс Афише. Дополнительно это можно проверить, оценив уникальное количество пользователей, сделавших хоть один заказ.
# 
# Дополнительно необходимо привести колонку с количеством дней между заказами к int и сократить размерность, так как это целое число. Таже для колонки с датой заказа тип datetime64 можно считать избыточным.

# ---
# 
# ###  2. Предобработка данных
# 
# Выполните все стандартные действия по предобработке данных:
# 
# ---
# 
# **Задача 2.1:** Данные о выручке сервиса представлены в российских рублях и казахстанских тенге. Приведите выручку к единой валюте — российскому рублю.
# 
# Для этого используйте датасет с информацией о курсе казахстанского тенге по отношению к российскому рублю за 2024 год — `final_tickets_tenge_df.csv`. Его можно загрузить по пути `https://code.s3.yandex.net/datasets/final_tickets_tenge_df.csv')`
# 
# Значения в рублях представлено для 100 тенге.
# 
# Результаты преобразования сохраните в новый столбец `revenue_rub`.
# 
# ---
# 

# In[12]:


exch_rate = pd.read_csv('https://code.s3.yandex.net/datasets/final_tickets_tenge_df.csv')


# In[13]:


exch_rate.info()


# In[14]:


exch_rate.head()


# In[15]:


df['order_dt'] = df['order_dt'].dt.date
exch_rate['data'] = pd.to_datetime(exch_rate['data']).dt.date


# In[16]:


def curs(row):
    if row['currency_code'] == 'kzt':
        date = row['order_dt']
        return(round((row['revenue']/100)*exch_rate[exch_rate['data']==date]['curs'].mean(),2))
    else:
        return row['revenue']


# In[17]:


df['revenue_rub'] = df.apply(curs, axis=1)


# ---
# 
# **Задача 2.2:**
# 
# - Проверьте данные на пропущенные значения. Если выгрузка из SQL была успешной, то пропуски должны быть только в столбце `days_since_prev`.
# - Преобразуйте типы данных в некоторых столбцах, если это необходимо. Обратите внимание на данные с датой и временем, а также на числовые данные, размерность которых можно сократить.
# - Изучите значения в ключевых столбцах. Обработайте ошибки, если обнаружите их.
#     - Проверьте, какие категории указаны в столбцах с номинальными данными. Есть ли среди категорий такие, что обозначают пропуски в данных или отсутствие информации? Проведите нормализацию данных, если это необходимо.
#     - Проверьте распределение численных данных и наличие в них выбросов. Для этого используйте статистические показатели, гистограммы распределения значений или диаграммы размаха.
#         
#         Важные показатели в рамках поставленной задачи — это выручка с заказа (`revenue_rub`) и количество билетов в заказе (`tickets_count`), поэтому в первую очередь проверьте данные в этих столбцах.
#         
#         Если обнаружите выбросы в поле `revenue_rub`, то отфильтруйте значения по 99 перцентилю.
# 
# После предобработки проверьте, были ли отфильтрованы данные. Если были, то оцените, в каком объёме. Сформулируйте промежуточный вывод, зафиксировав основные действия и описания новых столбцов.
# 
# ---

# In[18]:


df.isna().sum()


# In[19]:


df['days_since_prev'] = df['days_since_prev'].fillna(0)
df['days_since_prev'] = pd.to_numeric(df['days_since_prev'], downcast='integer')


# In[20]:


df.info()


# In[21]:


for i in ['device_type_canonical', 'currency_code', 'event_type_main', 'service_name', 'region_name', 'city_name']:
    print(f'Количество уникальных значний в {i} = {df[i].nunique()}: {df[i].sort_values().unique()}')
    print(df[i].value_counts())
    print()


# В столбце `event_type_main` есть категория мероприятия `другое`, что может означать отсутствие данных. 
# Оценим, сколько строк с таким значением и как распределяются эти значения по другим столбцам.

# In[22]:


print('Доля строк с мероприятием категрии "другое", %:')
print(round((df[df['event_type_main']=='другое'].shape[0]/df.shape[0])*100,2))


# In[23]:


for i in ['device_type_canonical', 'currency_code', 'service_name', 'region_name', 'city_name']:
    print(f'Распределение категории "другое" по столбцу {i}')
    print(df[i][df['event_type_main']=='другое'].value_counts())
    print()


# Данная категория не относится к какому либо значению, а количество таких данных более 20% от выборки, поэтому эти строки пока необходимо оставить без изменений.

# Оценим распределение численных данных и наличие в них выбросов.

# In[24]:


df[['revenue_rub','days_since_prev','tickets_count']].describe()


# In[25]:


boxplot = df.boxplot(column='revenue_rub',
                     vert=False, 
                     figsize=(15, 5))

boxplot.set_title('Распределение выручки заказа в рублях')
boxplot.set_xlabel('Выручка, руб')

plt.show()


# In[26]:


boxplot = df.boxplot(column='days_since_prev',
                     vert=False, 
                     figsize=(15, 5))

boxplot.set_title('Распределение количества дней между заказами')
boxplot.set_xlabel('Количество дней между заказами')

plt.show()


# In[27]:


boxplot = df.boxplot(column='tickets_count',
                     vert=False, 
                     figsize=(15, 5))

boxplot.set_title('Распределение количества билетов в заказе')
boxplot.set_xlabel('Количество билетов')

plt.show()


# В данных присутствуют заказы с большим количеством купленных билетов, которые являются выбросами, что отражается на сумме - в этом столбце тоже появляются выбросы. Возможно, такие заказы являются оптовыми, что может искажать статистику по обычным пользователям.
# 
# Выбросы в столбце с количеством дней между заказами необходимо оставить, так как это значение может быть разным для каждого пользования и поможет оценить активность.
# 
# Также в столбце с суммой присутствуют нулевые и отрицательные значения, оценим отдельно:

# In[28]:


print('Доля заказов с нулевой или отрицательной суммой, %:')
print(round((df.loc[df['revenue_rub']<=0].shape[0]/df.shape[0])*100,2))


# In[29]:


print('Доля заказов с аномальной суммой (более 99 перцентиля), %:')
print((df.loc[df['revenue_rub'] > df['revenue_rub'].quantile(0.99)].shape[0]/df.shape[0])*100)


# Удалим аномальные значения в столбце с суммой заказа.

# In[30]:


df_prev = df.copy()


# In[31]:


df = df.loc[(df['revenue_rub']>0)&(df['revenue_rub'] <= df['revenue_rub'].quantile(0.99))]


# Были проанализированы значения в категориальных столбцах, где было обнаружено и проанализировано значение категории мероприятия "другое". На данном этапе оставлено без изменений, так как такие данные составляют ~22% выборки.
# 
# Были оценены численные значения сумм заказов, количества билетов и дней между зазаками.
# Удалены аномальные значения по суммам заказов, так как они могут исказить статистику по покупкам пользователя, и оставлены без изменения данные по количеству дней между заказами, так как они наоборот помогает оценить активность каждого пользователя.

# In[32]:


print(f'В старом датафрейме {df_prev.shape[0]} строк')
print(f'В новом датафрейме {df.shape[0]} строк')
print(f'Удалено строк с аномальными значениями суммы заказа: {df_prev.shape[0] - df.shape[0]}, что составляет {round((1 - df.shape[0]/df_prev.shape[0])*100,2)}% от изначального датафрейма')


# ---
# 
# ### 3. Создание профиля пользователя
# 
# В будущем отдел маркетинга планирует создать модель для прогнозирования возврата пользователей. Поэтому сейчас они просят вас построить агрегированные признаки, описывающие поведение и профиль каждого пользователя.
# 
# ---
# 
# **Задача 3.1.** Постройте профиль пользователя — для каждого пользователя найдите:
# 
# - дату первого и последнего заказа;
# - устройство, с которого был сделан первый заказ;
# - регион, в котором был сделан первый заказ;
# - билетного партнёра, к которому обращались при первом заказе;
# - жанр первого посещённого мероприятия (используйте поле `event_type_main`);
# - общее количество заказов;
# - средняя выручка с одного заказа в рублях;
# - среднее количество билетов в заказе;
# - среднее время между заказами.
# 
# После этого добавьте два бинарных признака:
# 
# - `is_two` — совершил ли пользователь 2 и более заказа;
# - `is_five` — совершил ли пользователь 5 и более заказов.
# 
# **Рекомендация:** перед тем как строить профиль, отсортируйте данные по времени совершения заказа.
# 
# ---
# 

# In[33]:


df_agg = df.groupby('user_id', as_index=False).agg(
                                {'order_dt':'max', 
                                 'order_id':'count',
                                 'revenue_rub':'mean',
                                 'tickets_count':'mean',
                                 'days_since_prev':'mean'})


# In[34]:


df_agg = df_agg.rename(columns=
                       {'order_dt':'order_dt_max', 
                        'order_id':'order_id_count',
                        'revenue_rub':'revenue_rub_mean',
                        'tickets_count':'tickets_count_mean',
                        'days_since_prev':'days_since_prev_mean'})


# In[35]:


df_first = df.sort_values(by='order_ts').groupby('user_id', as_index=False).first()[['user_id','order_dt','device_type_canonical', 'region_name', 'service_name', 'event_type_main']]


# In[36]:


df_first = df_first.rename(columns=
                           {'order_dt':'order_dt_min',
                            'device_type_canonical':'device_type_first', 
                            'region_name':'region_name_first', 
                            'service_name':'service_name_first', 
                            'event_type_main':'event_type_first'})


# In[37]:


df_profile = df_agg.merge(df_first, on='user_id')


# In[38]:


df_profile['is_two'] = df_profile['order_id_count'].apply(lambda x: 1 if x >= 2 else 0)
df_profile['is_five'] = df_profile['order_id_count'].apply(lambda x: 1 if x >= 5 else 0)


# In[39]:


df_profile


# ---
# 
# **Задача 3.2.** Прежде чем проводить исследовательский анализ данных и делать выводы, важно понять, с какими данными вы работаете: насколько они репрезентативны и нет ли в них аномалий.
# 
# Используя данные о профилях пользователей, рассчитайте:
# 
# - общее число пользователей в выборке;
# - среднюю выручку с одного заказа;
# - долю пользователей, совершивших 2 и более заказа;
# - долю пользователей, совершивших 5 и более заказов.
# 
# Также изучите статистические показатели:
# 
# - по общему числу заказов;
# - по среднему числу билетов в заказе;
# - по среднему количеству дней между покупками.
# 
# По результатам оцените данные: достаточно ли их по объёму, есть ли аномальные значения в данных о количестве заказов и среднем количестве билетов?
# 
# Если вы найдёте аномальные значения, опишите их и примите обоснованное решение о том, как с ними поступить:
# 
# - Оставить и учитывать их при анализе?
# - Отфильтровать данные по какому-то значению, например, по 95-му или 99-му перцентилю?
# 
# Если вы проведёте фильтрацию, то вычислите объём отфильтрованных данных и выведите статистические показатели по обновлённому датасету.

# In[40]:


print(f"Общее число пользователей в выборке: {df_profile['user_id'].nunique()}")


# In[41]:


print(f"Средняя выручка с одного заказа: {round(df_profile['revenue_rub_mean'].mean(),2)}")


# In[42]:


print(f"Доля пользователей, совершивших 2 и более заказа: {round(df_profile['is_two'].mean()*100,2)}%")


# In[43]:


print(f"Доля пользователей, совершивших 5 и более заказов: {round(df_profile['is_five'].mean()*100,2)}%")


# In[44]:


df_profile[['order_id_count','tickets_count_mean','days_since_prev_mean']].describe(percentiles=[0.75, 0.95, 0.99])


# In[45]:


boxplot = df_profile.boxplot(column='order_id_count',
                     vert=False, 
                     figsize=(15, 5))

boxplot.set_title('Распределение количества заказов на пользователя')
boxplot.set_xlabel('Количество заказов')

plt.show()


# In[46]:


print("Оценим данные, если исключить строки более 99 перцентиля по полю 'order_id_count'")
df_profile[['order_id_count','tickets_count_mean','days_since_prev_mean']].loc[df_profile['order_id_count'] <= df_profile['order_id_count'].quantile(0.99)].describe()


# In[47]:


print("Оценим данные, если исключить строки более 95 перцентиля по полю 'order_id_count'")
df_profile[['order_id_count','tickets_count_mean','days_since_prev_mean']].loc[df_profile['order_id_count'] <= df_profile['order_id_count'].quantile(0.95)].describe()


# Выбросы в столбце 'order_id_count' корректируются, если ограничить датафрейм 99 перцентилем. Это поможет сохранить остальные данные, но при этом удалить выбросы.
# 
# В столбцах 'tickets_count_mean' и 'days_since_prev_mean' нет таких выбросов, которые необходимо удалять дополнительно.
# 
# Исходя из данных о среднем, медиане и стандартном отклонении, данные во всех столбцах не разбросаны слишком сильно. 
# Более 50% пользователей сделали либо 1 заказ, либо заказы в один день, что не является аномалией и не требует корректировки.

# In[48]:


df_profile_prev = df_profile.copy()
df_profile = df_profile.loc[df_profile['order_id_count'] <= df_profile['order_id_count'].quantile(0.99)]


# In[49]:


sns.histplot(data=df_profile, x='order_id_count', bins=100, kde=True)

plt.title('Распределение количества заказов на пользователя')
plt.ylabel('Количество заказов')
plt.show()


# In[50]:


print(f'В старом датафрейме {df_profile_prev.shape[0]} строк')
print(f'В новом датафрейме {df_profile.shape[0]} строк')
print(f'Удалено строк с аномальными значениями количества заказов: {df_profile_prev.shape[0] - df_profile.shape[0]}, что составляет {round((1 - df_profile.shape[0]/df_profile_prev.shape[0])*100,2)}% от изначального датафрейма с профилями пользователей')


# ---
# 
# ### 4. Исследовательский анализ данных
# 
# Следующий этап — исследование признаков, влияющих на возврат пользователей, то есть на совершение повторного заказа. Для этого используйте профили пользователей.

# 
# 
# #### 4.1. Исследование признаков первого заказа и их связи с возвращением на платформу
# 
# Исследуйте признаки, описывающие первый заказ пользователя, и выясните, влияют ли они на вероятность возвращения пользователя.
# 
# ---
# 
# **Задача 4.1.1.** Изучите распределение пользователей по признакам.
# 
# - Сгруппируйте пользователей:
#     - по типу их первого мероприятия;
#     - по типу устройства, с которого совершена первая покупка;
#     - по региону проведения мероприятия из первого заказа;
#     - по билетному оператору, продавшему билеты на первый заказ.
# - Подсчитайте общее количество пользователей в каждом сегменте и их долю в разрезе каждого признака. Сегмент — это группа пользователей, объединённых определённым признаком, то есть объединённые принадлежностью к категории. Например, все клиенты, сделавшие первый заказ с мобильного телефона, — это сегмент.
# - Ответьте на вопрос: равномерно ли распределены пользователи по сегментам или есть выраженные «точки входа» — сегменты с наибольшим числом пользователей?
# 
# ---
# 

# In[51]:


for i in ['event_type_first', 'device_type_first', 'region_name_first', 'service_name_first']:
    print(f'Распределение пользователей по сегментам категории {i}')
    print(df_profile[i].value_counts())
    print()
    print(f'Доля сегментов категории {i} от всей выборки в %')
    print(round((df_profile[i].value_counts()*100)/df_profile.shape[0],2))
    print()
    print('-----------------------------------------------------------')


# Наибольшая доля первых заказов пользователей (~45%) относится к сегменту концерты - это самы популярный тип мероприятий, для посещения которых пользователи приходят на платформу впервые.
# 
# В ~83%, то есть, 4 из 5 пользователей, используют для первого заказа мобильное устройство. Это удобный и современный способ покупки билетов.
# 
# Примерно 30% польщователей первый раз приобретают билеты на мероприятие, которое проводится в локации "Каменевский регион". Возможно, там проводится наибольшее количество мероприятий.
# 
# Наиболее часто (~23%) пользователи отдают предпочтение билетному оператору "Билеты без проблем", и по 13-14% пользователей в первый раз пользовались услугами операторов "Мой билет" и "Лови билет!". Возможно, эти операторы предлагают наилучшие цены на мероприятия, эксклюзивно сотрудничают с площадками проведения популярных мероприятий или специализируются на масштабных мероприятиях в крупных городах.

# ---
# 
# **Задача 4.1.2.** Проанализируйте возвраты пользователей:
# 
# - Для каждого сегмента вычислите долю пользователей, совершивших два и более заказа.
# - Визуализируйте результат подходящим графиком. Если сегментов слишком много, то поместите на график только 10 сегментов с наибольшим количеством пользователей. Такое возможно с сегментами по региону и по билетному оператору.
# - Ответьте на вопросы:
#     - Какие сегменты пользователей чаще возвращаются на Яндекс Афишу?
#     - Наблюдаются ли успешные «точки входа» — такие сегменты, в которых пользователи чаще совершают повторный заказ, чем в среднем по выборке?
# 
# При интерпретации результатов учитывайте размер сегментов: если в сегменте мало пользователей (например, десятки), то доли могут быть нестабильными и недостоверными, то есть показывать широкую вариацию значений.
# 
# ---
# 

# Рассчитаем общую долю пользователей с 2 и более заказами

# In[52]:


round(df_profile['is_two'].mean(),2)


# In[53]:


for i in ['event_type_first', 'device_type_first', 'region_name_first', 'service_name_first']:
    seg = round(df_profile.groupby(i)['is_two'].agg(['count', 'sum', 'mean']),2).sort_values(by='count',ascending=False).head(10)
    print(f'Доля пользователей, совершивших два и более заказа')
    print(seg)
    print()
    seg['mean'].plot.barh()
    plt.show()
    print('-----------------------------------------------------------')


# В выборке нет больших отклонений и колебаний ни в одном сегменте.
# 
# Можно обратить внимание, что реже всего возвращались пользователи, которые покупали билеты на спортивные мероприятия.
# Также, реже, чем остальные, возвращались пользователи,купившие билеты на мероприятия в Малиновоярском округе и Озернинском крае, однако, в абсолютном количестве это малая доля выборки данных.

# ---
# 
# **Задача 4.1.3.** Опираясь на выводы из задач выше, проверьте продуктовые гипотезы:
# 
# - **Гипотеза 1.** Тип мероприятия влияет на вероятность возврата на Яндекс Афишу: пользователи, которые совершили первый заказ на спортивные мероприятия, совершают повторный заказ чаще, чем пользователи, оформившие свой первый заказ на концерты.
# - **Гипотеза 2.** В регионах, где больше всего пользователей посещают мероприятия, выше доля повторных заказов, чем в менее активных регионах.
# 
# ---

# Гипотеза 1 не подтверждается: в сравнении с пользователями, совершившими первый заказ на спортивное мероприятие, посетители концертов совершали повторные заказы чаще.

# Гипотеза 2 требует дополнительной проверки: в топ-10 регионов, в которых пользователи посетили мероприятие, впервые купив билет на платформе, есть колебания доли пользователей с повторными заказами, однако количество данных по рахным регионам сильно варьируется, что искажает картину.

# ---
# 
# #### 4.2. Исследование поведения пользователей через показатели выручки и состава заказа
# 
# Изучите количественные характеристики заказов пользователей, чтобы узнать среднюю выручку сервиса с заказа и количество билетов, которое пользователи обычно покупают.
# 
# Эти метрики важны не только для оценки выручки, но и для оценки вовлечённости пользователей. Возможно, пользователи с более крупными и дорогими заказами более заинтересованы в сервисе и поэтому чаще возвращаются.
# 
# ---
# 
# **Задача 4.2.1.** Проследите связь между средней выручкой сервиса с заказа и повторными заказами.
# 
# - Постройте сравнительные гистограммы распределения средней выручки с билета (`avg_revenue_rub`):
#     - для пользователей, совершивших один заказ;
#     - для вернувшихся пользователей, совершивших 2 и более заказа.
# - Ответьте на вопросы:
#     - В каких диапазонах средней выручки концентрируются пользователи из каждой группы?
#     - Есть ли различия между группами?
# 
# Текст на сером фоне:
#     
# **Рекомендация:**
# 
# 1. Используйте одинаковые интервалы (`bins`) и прозрачность (`alpha`), чтобы визуально сопоставить распределения.
# 2. Задайте параметру `density` значение `True`, чтобы сравнивать форму распределений, даже если число пользователей в группах отличается.
# 
# ---
# 

# In[54]:


plt.figure(figsize=(15, 7))

min_value = df_profile['revenue_rub_mean'].min()
max_value = df_profile['revenue_rub_mean'].max() 

for i in df_profile['is_two'].unique():
    df_profile.loc[df_profile['is_two'] == i, 'revenue_rub_mean'].plot(
        kind='hist',
        density=True,
        bins=range(int(min_value), int(max_value)+1, 50),
        alpha=0.5,
        label=f'{i}',
        legend=True
    )

plt.title(f'Сравнение распределения средней выручки в зависимости от количества заказов')
plt.xlabel('Средняя сумма заказа')
plt.ylabel('Плотность вероятности')
plt.legend(title='Признак наличия 2 и более заказов')
plt.show() 


# Значения группы с одним заказом концентрируются в диапазоне от 0 до 500 рублей с наиболее вероятным 50, а значния пользователей, которые совершали другие заказы, расположены в диапазоне от 0 до 1000 рублей с наиболее вероятным значением 500.
# 
# Дополнительно можно отметить, что пользователи, не делавшие повторых заказов, с большей вероятностью делали крупные покупки, чем те, кто возвращался на платформу.
# Возможно, пользователи с повторными заказами тоже совершали крупные заказы, но, так как оценивается среднее стоимости всех заказов, информация об этом сгладилась.

# ---
# 
# **Задача 4.2.2.** Сравните распределение по средней выручке с заказа в двух группах пользователей:
# 
# - совершившие 2–4 заказа;
# - совершившие 5 и более заказов.
# 
# Ответьте на вопрос: есть ли различия по значению средней выручки с заказа между пользователями этих двух групп?
# 
# ---
# 

# In[55]:


plt.figure(figsize=(15, 7))

min_value = df_profile.loc[df_profile['is_two'] == 1, 'revenue_rub_mean'].min()
max_value = df_profile.loc[df_profile['is_two'] == 1, 'revenue_rub_mean'].max()

df_profile.loc[df_profile['is_five'] == 1, 'revenue_rub_mean'].plot(
        kind='hist',
        density=True,
        bins=range(int(min_value), int(max_value)+1, 50),
        alpha=0.5,
        label=f'5 и более заказов',
        legend=True
    )
df_profile.loc[(df_profile['is_two'] - df_profile['is_five']) == 1, 'revenue_rub_mean'].plot(
        kind='hist',
        density=True,
        bins=range(int(min_value), int(max_value)+1, 50),
        alpha=0.5,
        label=f'2–4 заказа',
        legend=True
    )

plt.title(f'Сравнение распределения средней выручки в зависимости от количества заказов')
plt.xlabel('Средняя сумма заказа')
plt.ylabel('Плотность вероятности')
plt.legend(title='Количество заказов')
plt.show() 


# Различия между группами есть:
# * В группе с 5 и более заказами средняя сумма явно локализуется в диапазоне от 200 до 800 с максимом примерно в значении 500
# * В группе 2-4 заказов средняя сумма смещена влево, к суммам от 0 до 500
# * Крупные заказы более характерны для группа с 2-4 заказами, однако, из-за бОльшего количества заказов во второй группе, её показатели могли усредниться.

# ---
# 
# **Задача 4.2.3.** Проанализируйте влияние среднего количества билетов в заказе на вероятность повторной покупки.
# 
# - Изучите распределение пользователей по среднему количеству билетов в заказе (`avg_tickets_count`) и опишите основные наблюдения.
# - Разделите пользователей на несколько сегментов по среднему количеству билетов в заказе:
#     - от 1 до 2 билетов;
#     - от 2 до 3 билетов;
#     - от 3 до 5 билетов;
#     - от 5 и более билетов.
# - Для каждого сегмента подсчитайте общее число пользователей и долю пользователей, совершивших повторные заказы.
# - Ответьте на вопросы:
#     - Как распределены пользователи по сегментам — равномерно или сконцентрировано?
#     - Есть ли сегменты с аномально высокой или низкой долей повторных покупок?
# 
# ---

# In[56]:


df_profile['tickets_count_mean'].plot(
        kind='hist',
  #      density=True,
        bins=30,
        alpha=0.5,
        legend=True
    )

plt.title(f'Распределение пользователей по среднему количеству билетов в заказе')
plt.xlabel('Среднее количество билетов')
plt.ylabel('Количество пользователей')
plt.show()


# В основном среднее количество билетов варьруется от 2 до 4 штук.

# In[57]:


def ticket_group(cnt):
    if cnt < 2:
        return 'от 1 до 2 билетов'
    if cnt < 3:
        return 'от 2 до 3 билетов'
    if cnt < 5:
        return 'от 3 до 5 билетов'
    else:
        return 'от 5 и более билетов'
    


# In[58]:


df_profile['tickets_count_group'] = df_profile['tickets_count_mean'].apply(ticket_group)


# In[59]:


print(f'Распределение пользователей по среднему количеству билетов')
print(df_profile['tickets_count_group'].value_counts())


# In[60]:


print(f'Пользователи, совершившие повторные заказы в каждом сегменте')
print(round(df_profile.groupby('tickets_count_group')['is_two'].agg(['count','sum', 'mean']),2).sort_values(by='count',ascending=False))


# Основная часть пользователей в среднем покупают от 2 до 3 или от 3 до 4 билетов, а более в среднем 5 билетов покупают меньше 3% пользователей.
# 
# В сегменте, где среднее количество билетов в заказе от 2 до 3 билетов наибольшая доля пользователей с повторными покупками - 73%, а наименьшая, менее 20%, в сегменте от 5 и более билетов. В остальных группах этот показатель равент 51-54%&

# ---
# 
# #### 4.3. Исследование временных характеристик первого заказа и их влияния на повторные покупки
# 
# Изучите временные параметры, связанные с первым заказом пользователей:
# 
# - день недели первой покупки;
# - время с момента первой покупки — лайфтайм;
# - средний интервал между покупками пользователей с повторными заказами.
# 
# ---
# 
# **Задача 4.3.1.** Проанализируйте, как день недели, в которой была совершена первая покупка, влияет на поведение пользователей.
# 
# - По данным даты первого заказа выделите день недели.
# - Для каждого дня недели подсчитайте общее число пользователей и долю пользователей, совершивших повторные заказы. Результаты визуализируйте.
# - Ответьте на вопрос: влияет ли день недели, в которую совершена первая покупка, на вероятность возврата клиента?
# 
# ---
# 

# In[61]:


df_profile['order_first_week_day'] = pd.to_datetime(df_profile['order_dt_min']).dt.weekday


# In[62]:


print(f'Пользователи, совершившие повторные заказы в каждом сегменте')
print(round(df_profile.groupby('order_first_week_day')['is_two'].agg(['count','sum', 'mean']),2).sort_values(by='count',ascending=False))


# In[63]:


round(df_profile.groupby('order_first_week_day')['is_two'].agg(['mean']),2).plot.barh()
plt.show()


# День недели несущественно влияет на вероятность возврата.

# ---
# 
# **Задача 4.3.2.** Изучите, как средний интервал между заказами влияет на удержание клиентов.
# 
# - Рассчитайте среднее время между заказами для двух групп пользователей:
#     - совершившие 2–4 заказа;
#     - совершившие 5 и более заказов.
# - Исследуйте, как средний интервал между заказами влияет на вероятность повторного заказа, и сделайте выводы.
# 
# ---
# 

# Среднее время между заказами у пользователей, совершивших 2-4 заказа:

# In[64]:


round(df_profile.loc[(df_profile['is_two'] - df_profile['is_five']) == 1, 'days_since_prev_mean'].mean(),2)


# Среднее время между заказами у пользователей, совершивших 5 и более заказов:

# In[65]:


round(df_profile.loc[df_profile['is_five'] == 1, 'days_since_prev_mean'].mean(),2)


# In[66]:


plt.figure(figsize=(15, 7))

min_value = df_profile.loc[df_profile['is_two'] == 1, 'days_since_prev_mean'].min()
max_value = df_profile.loc[df_profile['is_two'] == 1, 'days_since_prev_mean'].max()

df_profile.loc[df_profile['is_five'] == 1, 'days_since_prev_mean'].plot(
        kind='hist',
        density=True,
        bins=range(int(min_value), int(max_value)+1, 1),
        alpha=0.5,
        label=f'5 и более заказов',
        legend=True
    )
df_profile.loc[(df_profile['is_two'] - df_profile['is_five']) == 1, 'days_since_prev_mean'].plot(
        kind='hist',
        density=True,
        bins=range(int(min_value), int(max_value)+1, 1),
        alpha=0.5,
        label=f'2–4 заказа',
        legend=True
    )

plt.title(f'Сравнение распределения среднего количества дней между заказами')
plt.xlabel('Средняя количество дней между заказами')
plt.ylabel('Плотность вероятности')
plt.legend(title='Количество заказов')
plt.show()


# У пользователей, совершивших от 2 до 4 заказов, среднее количество дней, преимущественно, до 5. Возможно, это пользователи, которые докупают недостающие билеты на одни и те же мероприятия, поэтому количество заказов растет, а количество дней достаточно мало, чтобы это были разные мероприятия. В остальных случаях количество дней распределяется равномерно.
# 
# У пользователей, совершивших более 5 заказов, среднее время между заказами больше, основная масса сосредоточена от 3 до 8 дней между покупками. Возможно, это люди, которые регулярно посещают мероприятия, поэтому количество заказов может быть связано с количеством мероприятий, которое проводилось за исследуемый период.

# ---
# 
# #### 4.4. Корреляционный анализ количества покупок и признаков пользователя
# 
# Изучите, какие характеристики первого заказа и профиля пользователя могут быть связаны с числом покупок. Для этого используйте универсальный коэффициент корреляции `phi_k`, который позволяет анализировать как числовые, так и категориальные признаки.
# 
# ---
# 
# **Задача 4.4.1:** Проведите корреляционный анализ:
# - Рассчитайте коэффициент корреляции `phi_k` между признаками профиля пользователя и числом заказов (`total_orders`). При необходимости используйте параметр `interval_cols` для определения интервальных данных.
# - Проанализируйте полученные результаты. Если полученные значения будут близки к нулю, проверьте разброс данных в `total_orders`. Такое возможно, когда в данных преобладает одно значение: в таком случае корреляционный анализ может показать отсутствие связей. Чтобы этого избежать, выделите сегменты пользователей по полю `total_orders`, а затем повторите корреляционный анализ. Выделите такие сегменты:
#     - 1 заказ;
#     - от 2 до 4 заказов;
#     - от 5 и выше.
# - Визуализируйте результат корреляции с помощью тепловой карты.
# - Ответьте на вопрос: какие признаки наиболее связаны с количеством заказов?
# 
# ---

# In[67]:


correlation_matrix = df_profile.phik_matrix()

print('Корреляционная матрица с коэффициентом phi_k для переменной order_id_count')
correlation_matrix.loc[correlation_matrix.index != 'order_id_count'][['order_id_count']].sort_values(by='order_id_count', ascending=False) 


# На данном этапе анализ не показал связей, потому что сильная связь есть только с полями, которые рассчитаны на основе поля order_id_count, а так же с датой первого и последнего заказа, что, возможно, говорит о том, что чем дольше пользователь пользуется платформой, тем больше заказов он успел сделать.
# 
# Разделим клиентов на группы по количеству заказов и уберем лишние поля, взяимосвязь с которыми не будет показательна.

# In[68]:


df_profile['order_count_group'] = df_profile['order_id_count'].apply(lambda x: '1 заказ' if x == 1 
                                                                     else 'от 2 до 4 заказов' if x < 5 
                                                                     else 'от 5 и выше')


# In[72]:


df_profile['order_count_group'].value_counts()


# In[69]:


df_profile.columns


# In[70]:


correlation_matrix = df_profile[['order_dt_max', 'revenue_rub_mean',
       'tickets_count_mean', 'days_since_prev_mean', 'order_dt_min',
       'device_type_first', 'region_name_first', 'service_name_first',
       'event_type_first', 'tickets_count_group',
       'order_first_week_day', 'order_count_group']].phik_matrix()
    
print('Корреляционная матрица с коэффициентом phi_k для переменной order_count_group')
correlation_matrix.loc[correlation_matrix.index != 'order_count_group'][['order_count_group']].sort_values(by='order_count_group', ascending=False) 


# In[71]:


data_heatmap = correlation_matrix.loc[correlation_matrix.index != 'order_count_group'][['order_count_group']].sort_values(by='order_count_group', ascending=False) 
sns.heatmap(data_heatmap,
            annot=True, 
            fmt='.2f', 
            cmap='coolwarm',
            linewidths=0.5,
            cbar=False
           )

plt.title('Тепловая карта коэффициента phi_k для данных order_count_group')

plt.show() 


# По обновленным данным видно, что есть зависимость количества заказов от даты первого и последнего заказов. Это может быть связано со временем, в течение которого пользователь использует платформу. Зависимость от даты последнего заказа может быть связана с тем, что, во-певых, пользователи с небольшим промежтком между заказами докупают билеты, во-вторых, с большим количеством (более 30%) пользователей, совершивших только один заказ.
# 
# Менее сильная зависимость наблюдается с полями tickets_count_mean и revenue_rub_mean. Как исследовалось ранее, в отдельных группах пользователей действительно есть зависимость между данными о количестве купленных билетов и средней сумме заказа. Важно отметить, что эти поля также напрямую связаны между собой линейно, так как сумма заказа зависит как от стоимости билетов, так и от их количества.

# ### 5. Общий вывод и рекомендации
# 
# В конце проекта напишите общий вывод и рекомендации: расскажите заказчику, на что нужно обратить внимание. В выводах кратко укажите:
# 
# - **Информацию о данных**, с которыми вы работали, и то, как они были подготовлены: например, расскажите о фильтрации данных, переводе тенге в рубли, фильтрации выбросов.
# - **Основные результаты анализа.** Например, укажите:
#     - Сколько пользователей в выборке? Как распределены пользователи по числу заказов? Какие ещё статистические показатели вы подсчитали важным во время изучения данных?
#     - Какие признаки первого заказа связаны с возвратом пользователей?
#     - Как связаны средняя выручка и количество билетов в заказе с вероятностью повторных покупок?
#     - Какие временные характеристики влияют на удержание (день недели, интервалы между покупками)?
#     - Какие характеристики первого заказа и профиля пользователя могут быть связаны с числом покупок согласно результатам корреляционного анализа?
# - Дополните выводы информацией, которая покажется вам важной и интересной. Следите за общим объёмом выводов — они должны быть компактными и ёмкими.
# 
# В конце предложите заказчику рекомендации о том, как именно действовать в его ситуации. Например, укажите, на какие сегменты пользователей стоит обратить внимание в первую очередь, а какие нуждаются в дополнительных маркетинговых усилиях.

# На основе анализа данных о покупках был проведен ряд этапов предобработки для обеспечения качества данных:
# 
# **Исходные данные:** 290611 заказов
# 
# **После объединения и очистки:** 281879 заказов (удалено 8732 строки, 3.0%)
# 
# Причины удаления строк: 
# * Аномальные суммы заказов - удалены заказы с высокими суммами, которые могли исказить статистику по типичным пользовательским покупкам.
# * Профили пользователей - на основе очищенных данных построены профили 21483 пользователей
# 
# **Дополнительная очистка профилей:** Удалено 217 строк (1.0%) с аномально высоким количеством заказов (ограничение по 99-му процентилю) для исключения редких случаев, не репрезентативных для общей картины поведения.
# 
# 
# **Ключевые выводы о поведении пользователей:**
# 
# Лояльность формируется после второго заказа. Пользователи, совершившие второй заказ, часто переходят к 5 и более покупкам.
# 
# **Портрет возвращающегося пользователя:**
# 
# * Первый заказ: Чаще на концерты (45% первых покупок). Покупатели билетов на спортивные события возвращаются реже.
# * Устройство: 83% используют мобильные устройства.
# * Средний чек: Средняя сумма повторных заказов составляет 500-1000 рублей.
# * Количество билетов: Наиболее лояльны пользователи, покупающие в среднем 2-3 билета за раз (73% из них возвращаются).
# * Регулярность: Самые активные пользователи (5+ заказов) совершают новые покупки каждые 3-8 дней.

# Рекомендации для команды маркетинга
# 
# * Рекламные кампании и коммуникации оптимизировать под мобильные устройства.
# * Сделать концерты ключевым предложением для привлечения новой аудитории.
# 
# Стимулирование второго заказа:
# 
# * Выделять пользователей после первой покупки 2-3 билетов на концерт и предлагать им персональные скидки на следующее мероприятие. Главная цель- перевести их через порог второго заказа.
# 
# Удержание клиентов:
# 
# * Для пользователей с 2-4 заказами внедрить сервисы "докупки билетов" и персонализированные рекомендации на основе их предыдущих покупок.
# * Для пользователей, купивших билеты на спорт или сделавших разовый крупный заказ, разработать отдельную стратегию, предлагая им контент из других категорий мероприятий.

# ### 6. Финализация проекта и публикация в Git
# 
# Когда вы закончите анализировать данные, оформите проект, а затем опубликуйте его.
# 
# Выполните следующие действия:
# 
# 1. Создайте файл `.gitignore`. Добавьте в него все временные и чувствительные файлы, которые не должны попасть в репозиторий.
# 2. Сформируйте файл `requirements.txt`. Зафиксируйте все библиотеки, которые вы использовали в проекте.
# 3. Вынести все чувствительные данные (параметры подключения к базе) в `.env`файл.
# 4. Проверьте, что проект запускается и воспроизводим.
# 5. Загрузите проект в публичный репозиторий — например, на GitHub. Убедитесь, что все нужные файлы находятся в репозитории, исключая те, что в `.gitignore`. Ссылка на репозиторий понадобится для отправки проекта на проверку. Вставьте её в шаблон проекта в тетрадке Jupyter Notebook перед отправкой проекта на ревью.

# **Вставьте ссылку на проект в этой ячейке тетрадки перед отправкой проекта на ревью.**
